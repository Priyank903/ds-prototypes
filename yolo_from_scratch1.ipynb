{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-12-23T15:04:43.875483Z",
          "iopub.status.busy": "2023-12-23T15:04:43.874788Z",
          "iopub.status.idle": "2023-12-23T15:04:58.247641Z",
          "shell.execute_reply": "2023-12-23T15:04:58.246793Z",
          "shell.execute_reply.started": "2023-12-23T15:04:43.875450Z"
        },
        "trusted": true,
        "id": "7l-psMsBArhj",
        "outputId": "f0326438-9833-4db0-cc7d-2d0ed8e580a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import  xml.etree.ElementTree as ET\n",
        "import cv2\n",
        "import shutil\n",
        "from tensorflow.keras.layers import Conv2D,BatchNormalization,LeakyReLU,Flatten,Dense,Dropout,Reshape\n",
        "import albumentations as A\n",
        "from tensorflow.keras.callbacks import (Callback, CSVLogger, EarlyStopping, LearningRateScheduler,\n",
        "                                        ModelCheckpoint, ReduceLROnPlateau)\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "train_images=\"/kaggle/input/pascal-voc-2012-dataset/VOC2012_train_val/VOC2012_train_val/JPEGImages/\"\n",
        "train_maps=\"/kaggle/input/pascal-voc-2012-dataset/VOC2012_train_val/VOC2012_train_val/Annotations/\"\n",
        "\n",
        "classes=['aeroplane','bicycle','bird','boat','bottle','bus','car','cat','chair','cow','diningtable','dog','horse','motorbike','person','pottedplant','sheep','sofa','train','tvmonitor']\n",
        "\n",
        "B=2\n",
        "N_CLASSES=len(classes)\n",
        "H,W=224,224\n",
        "SPLIT_SIZE=int(H/32)\n",
        "N_EPOCHS=135\n",
        "BATCH_SIZE=32\n",
        "# Data Preparation\n",
        "def preprocess_xml(filename):\n",
        "    tree=ET.parse(filename)\n",
        "    root=tree.getroot()\n",
        "    size_tree=root.find('size')\n",
        "    height=float(size_tree.find('height').text)\n",
        "    width=float(size_tree.find('width').text)\n",
        "    bounding_boxes=[]\n",
        "    class_dict={classes[i]:i for i in range(len(classes))}\n",
        "    for object_tree in root.findall('object'):\n",
        "        for bounding_box in object_tree.iter('bndbox'):\n",
        "            xmin=float(bounding_box.find('xmin').text)\n",
        "            xmax=float(bounding_box.find('xmax').text)\n",
        "            ymin=float(bounding_box.find('ymin').text)\n",
        "            ymax=float(bounding_box.find('ymax').text)\n",
        "            break\n",
        "        class_name=object_tree.find('name').text\n",
        "        bounding_box=[\n",
        "                (xmin+xmax)/(2*width),\n",
        "                (ymin+ymax)/(2*height),\n",
        "                (xmax-xmin)/width,\n",
        "                (ymax-ymin)/height,\n",
        "                class_dict[class_name]\n",
        "        ]\n",
        "        bounding_boxes.append(bounding_box)\n",
        "    return tf.convert_to_tensor(bounding_boxes)\n",
        "\n",
        "\n",
        "preprocess_xml(train_maps+\"2007_000032.xml\")\n",
        "def generate_output(bounding_boxes):\n",
        "  output_label=np.zeros((SPLIT_SIZE,SPLIT_SIZE,N_CLASSES+5))\n",
        "  for b in range(len(bounding_boxes)):\n",
        "    grid_x=bounding_boxes[...,b,0]*SPLIT_SIZE\n",
        "    grid_y=bounding_boxes[...,b,1]*SPLIT_SIZE\n",
        "    i=int(grid_x)\n",
        "    j=int(grid_y)\n",
        "\n",
        "    output_label[i,j,0:5]=[1.,grid_x%1,grid_y%1,bounding_boxes[...,b,2],bounding_boxes[...,b,3]]\n",
        "    output_label[i,j,5+int(bounding_boxes[...,b,4])]=1.\n",
        "\n",
        "  return tf.convert_to_tensor(output_label,tf.float32)\n",
        "generate_output(preprocess_xml(train_maps+\"2007_000032.xml\"))[0,5]\n",
        "\n",
        "val_list=['2007_000027.jpg','2007_000032.jpg','2007_000033.jpg','2007_000039.jpg','2007_000042.jpg','2007_000061.jpg',\n",
        "          '2007_000063.jpg','2007_000068.jpg','2007_000121.jpg','2007_000123.jpg','2007_000129.jpg','2007_000170.jpg',\n",
        "          '2007_000175.jpg','2007_000187.jpg','2007_000241.jpg','2007_000243.jpg','2007_000250.jpg','2007_000256.jpg',\n",
        "          '2007_000272.jpg','2007_000323.jpg','2007_000332.jpg','2007_000333.jpg','2007_000346.jpg','2007_000363.jpg',\n",
        "          '2007_000364.jpg','2007_000392.jpg','2007_000423.jpg','2007_000452.jpg','2007_000464.jpg','2007_000480.jpg',\n",
        "          '2007_000491.jpg','2007_000504.jpg','2007_000515.jpg','2007_000528.jpg','2007_000529.jpg','2007_000549.jpg',\n",
        "          '2007_000559.jpg','2007_000572.jpg','2007_000584.jpg','2007_000629.jpg','2007_000636.jpg','2007_000645.jpg',\n",
        "          '2007_000648.jpg','2007_000661.jpg','2007_000663.jpg','2007_000664.jpg','2007_000676.jpg','2007_000713.jpg',\n",
        "          '2007_000720.jpg','2007_000727.jpg','2007_000733.jpg','2007_000738.jpg','2007_000762.jpg','2007_000768.jpg',\n",
        "          '2007_000783.jpg','2007_000793.jpg','2007_000799.jpg','2007_000804.jpg','2007_000807.jpg','2007_000822.jpg',\n",
        "          '2007_001299.jpg','2007_001311.jpg','2007_001321.jpg','2007_001340.jpg']\n",
        "\n",
        "!mkdir /kaggle/working/val_images\n",
        "!mkdir /kaggle/working/val_maps\n",
        "val_images='/kaggle/working/val_images/'\n",
        "val_maps='/kaggle/working/val_maps/'\n",
        "\n",
        "for name in val_list:\n",
        "    shutil.copy(train_maps+name[:-3]+'xml',val_maps+name[:-3]+'xml')\n",
        "    shutil.copy(train_images+name,val_images+name)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "im_paths=[]\n",
        "xml_paths=[]\n",
        "\n",
        "val_im_paths=[]\n",
        "val_xml_paths=[]\n",
        "\n",
        "\n",
        "for i in os.listdir(train_maps):\n",
        "    if((i[:-3]+'jpg') in val_list):\n",
        "        continue\n",
        "    im_paths.append(train_images+i[:-3]+'jpg')\n",
        "    xml_paths.append(train_maps+i)\n",
        "\n",
        "\n",
        "\n",
        "for i in os.listdir(val_maps):\n",
        "    val_im_paths.append(val_images+i[:-3]+'jpg')\n",
        "    val_xml_paths.append(val_maps+i)\n",
        "\n",
        "print(len(im_paths),len(xml_paths))\n",
        "print(len(val_im_paths),len(val_xml_paths))\n",
        "train=tf.data.Dataset.from_tensor_slices((im_paths,xml_paths))\n",
        "val=tf.data.Dataset.from_tensor_slices((val_im_paths,val_xml_paths))\n",
        "for i in val.take(1):\n",
        "    print(i)\n",
        "def get_imbboxes(im_path,xml_path):\n",
        "    img=tf.io.decode_jpeg(tf.io.read_file(im_path))\n",
        "    img=tf.cast(tf.image.resize(img,size=[H,W]),dtype=tf.float32)\n",
        "\n",
        "    bboxes=tf.numpy_function(func=preprocess_xml,inp=[xml_path],Tout=tf.float32)\n",
        "\n",
        "    return img,bboxes\n",
        "train=train.map(get_imbboxes)\n",
        "val=val.map(get_imbboxes)\n",
        "for i,j in val.take(1):\n",
        "    print(i,j)\n",
        "    cv2.imwrite('out_1.jpg',np.array(i))\n",
        "transforms = A.Compose([\n",
        "    A.Resize(H,W),\n",
        "    A.RandomCrop(\n",
        "         width=np.random.randint(int(0.9*W),W),\n",
        "         height=np.random.randint(int(0.9*H),H), p=0.5),\n",
        "    A.RandomScale(scale_limit=0.1, interpolation=cv2.INTER_LANCZOS4,p=0.5),\n",
        "    A.HorizontalFlip(p=0.5,),\n",
        "    A.Resize(H,W),\n",
        "\n",
        "], bbox_params=A.BboxParams(format='yolo', ))\n",
        "def aug_albument(image,bboxes):\n",
        "  augmented=transforms(image=image,bboxes=bboxes)\n",
        "  return [tf.convert_to_tensor(augmented[\"image\"],dtype=tf.float32),\n",
        "          tf.convert_to_tensor(augmented[\"bboxes\"],dtype=tf.float32)]\n",
        "def process_data(image,bboxes):\n",
        "    aug= tf.numpy_function(func=aug_albument, inp=[image,bboxes], Tout=(tf.float32,tf.float32))\n",
        "    return aug[0],aug[1]\n",
        "train=train.map(process_data)\n",
        "for i,j in train.skip(2):\n",
        "  print(i.shape,j)\n",
        "  break\n",
        "cv2.imwrite('out_2.jpg',np.array(i))\n",
        "def preprocess_augment(img,y):\n",
        "  img = tf.image.random_brightness(img, max_delta=50.)\n",
        "  img = tf.image.random_saturation(img, lower=0.5, upper=1.5)\n",
        "  img = tf.image.random_contrast(img, lower=0.5, upper=1.5)\n",
        "  #img = tf.image.random_hue(img, max_delta=0.5 )\n",
        "  img = tf.clip_by_value(img, 0, 255)\n",
        "  labels=tf.numpy_function(func=generate_output, inp=[y], Tout=(tf.float32))\n",
        "  return img,labels\n",
        "def preprocess(img,y):\n",
        "  img = tf.cast(tf.image.resize(img, size=[H, W]), dtype=tf.float32)\n",
        "\n",
        "  labels=tf.numpy_function(func=generate_output, inp=[y], Tout=(tf.float32))\n",
        "  return img,labels\n",
        "train=train.map(preprocess_augment)\n",
        "val=val.map(preprocess)\n",
        "train=(\n",
        "    train\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "\n",
        "val=(\n",
        "    val\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(tf.data.AUTOTUNE)\n",
        ")\n",
        "# Modeling\n",
        "NUM_FILTERS=512\n",
        "OUTPUT_DIM=int(N_CLASSES+5*B)\n",
        "base_model=tf.keras.applications.ResNet50(\n",
        "    weights='imagenet',\n",
        "    input_shape=(H,W,3),\n",
        "    include_top=False,\n",
        ")\n",
        "base_model.trainable=False\n",
        "model=tf.keras.Sequential([\n",
        "    base_model,\n",
        "    Conv2D(NUM_FILTERS,(3,3),padding='same',kernel_initializer='he_normal'),\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "\n",
        "\n",
        "    Conv2D(NUM_FILTERS,(3,3),padding='same',kernel_initializer='he_normal'),\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "\n",
        "    Conv2D(NUM_FILTERS,(3,3),padding='same',kernel_initializer='he_normal'),\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    Dense(NUM_FILTERS,kernel_initializer='he_normal'),\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(alpha=0.1),\n",
        "\n",
        "\n",
        "    Dense(int(SPLIT_SIZE*SPLIT_SIZE*OUTPUT_DIM),activation='sigmoid'),\n",
        "\n",
        "    Reshape((int(SPLIT_SIZE),int(SPLIT_SIZE),OUTPUT_DIM))\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "def compute_iou(boxes1,boxes2):\n",
        "    boxes1_t=tf.stack([boxes1[...,0]-boxes1[...,2]/2,\n",
        "                       boxes1[...,1]-boxes1[...,3]/2,\n",
        "                       boxes1[...,0]+boxes1[...,2]/2,\n",
        "                       boxes1[...,1]+boxes1[...,3]/2],axis=-1)\n",
        "\n",
        "\n",
        "    boxes2_t=tf.stack([boxes2[...,0]-boxes2[...,2]/2,\n",
        "                       boxes2[...,1]-boxes2[...,3]/2,\n",
        "                       boxes2[...,0]+boxes2[...,2]/2,\n",
        "                       boxes2[...,1]+boxes2[...,3]/2],axis=-1)\n",
        "\n",
        "    lu=tf.maximum(boxes1_t[...,:2],boxes2_t[...,2:])\n",
        "    rd=tf.minimum(boxes1_t[...,2:],boxes2_t[...,2:])\n",
        "\n",
        "    intersection=tf.maximum(0.0,rd-lu)\n",
        "    inter_square=intersection[...,0]*intersection[...,1]\n",
        "\n",
        "    square1=boxes1[...,2]*boxes1[...,3]\n",
        "    square2=boxes2[...,2]*boxes2[...,3]\n",
        "\n",
        "    union_square=tf.maximum(square1+square2-inter_square,1e-10)\n",
        "\n",
        "    return tf.clip_by_value((inter_square/union_square),0.0,1.0)\n",
        "\n",
        "def difference(x,y):\n",
        "    return tf.reduce_sum(tf.square(y-x))\n",
        "def yolo_loss(y_true,y_pred):\n",
        "    target=y_true[...,0]\n",
        "    #--------------------------------------- for object\n",
        "    y_pred_extract=tf.gather_nd(y_pred,tf.where(target[:]==1))\n",
        "    y_target_extract=tf.gather_nd(y_true,tf.where(target[:]==1))\n",
        "\n",
        "    rescaler=tf.where(target[:]==1)*32\n",
        "\n",
        "    upscaler_1=tf.concat([rescaler[:,1:],tf.zeros([len(rescaler),2],dtype=tf.int64)],axis=-1)\n",
        "\n",
        "\n",
        "    target_upscaler_2=tf.repeat([[32.,32.,224.,224.]],\n",
        "                                repeats=[len(rescaler)],axis=0)*tf.cast(y_target_extract[...,1:5],dtype=tf.float32)\n",
        "    pred_1_upscaler_2=tf.repeat([[32.,32.,224.,224.]],repeats=[len(rescaler)],axis=0)*tf.cast(y_pred_extract[...,1:5],dtype=tf.float32)\n",
        "    pred_2_upscaler_2=tf.repeat([[32.,32.,224.,224.]],repeats=[len(rescaler)],axis=0)*tf.cast(y_pred_extract[...,6:10],dtype=tf.float32)\n",
        "\n",
        "\n",
        "    target_original=tf.cast(upscaler_1,dtype=tf.float32)+target_upscaler_2\n",
        "    pred_1_original=tf.cast(upscaler_1,dtype=tf.float32)+pred_1_upscaler_2\n",
        "    pred_2_original=tf.cast(upscaler_1,dtype=tf.float32)+pred_2_upscaler_2\n",
        "\n",
        "    mask=tf.cast(tf.math.greater(compute_iou(target_original,pred_2_original),compute_iou(target_original,pred_1_original)),dtype=tf.int32)\n",
        "\n",
        "    y_pred_joined=tf.transpose(tf.concat([tf.expand_dims(y_pred_extract[...,0],axis=0),tf.expand_dims(y_pred_extract[...,5],axis=0)],axis=-1))\n",
        "\n",
        "    obj_pred=tf.gather_nd(y_pred_joined,tf.stack([tf.range(len(rescaler)),mask],axis=-1))\n",
        "\n",
        "    object_loss=difference(tf.cast(obj_pred,dtype=tf.float32),tf.cast(tf.ones([len(rescaler)]),dtype=tf.float32))\n",
        "\n",
        "    #------------------------------------------------------ for no object\n",
        "\n",
        "    y_pred_extract=tf.gather_nd(y_pred[...,0:B*5],tf.where(target[:]==0))\n",
        "\n",
        "    y_target_extract=tf.zeros(len(y_pred_extract))\n",
        "\n",
        "    no_obj_loss_1=difference(tf.cast(y_pred_extract[...,0],dtype=tf.float32),tf.cast(y_target_extract,dtype=tf.float32))\n",
        "\n",
        "    no_obj_loss_2=difference(tf.cast(y_pred_extract[...,5],dtype=tf.float32),tf.cast(y_target_extract,dtype=tf.float32))\n",
        "\n",
        "    no_obj_loss=no_obj_loss_1+no_obj_loss_2\n",
        "\n",
        "    #-------------------------------------------------------- for object class loss\n",
        "\n",
        "    y_pred_extract=tf.gather_nd(y_pred[...,10:],tf.where(target[:]==1))\n",
        "    class_extract=tf.gather_nd(y_true[...,5:],tf.where(target[:]==1))\n",
        "\n",
        "    class_loss=difference(tf.cast(y_pred_extract,dtype=tf.float32),tf.cast(class_extract,dtype=tf.float32))\n",
        "\n",
        "    #--------------------------------------------------------- for object center loss\n",
        "\n",
        "    y_pred_extract=tf.gather_nd(y_pred[...,0:B*5],tf.where(target[:]==1))\n",
        "    center_joined=tf.stack([y_pred_extract[...,1:3],y_pred_extract[...,6:8]],axis=1)\n",
        "    center_pred=tf.gather_nd(center_joined,tf.stack([tf.range(len(rescaler)),mask],axis=-1))\n",
        "    center_target=tf.gather_nd(y_true[...,1:3],tf.where(target[:]==1))\n",
        "\n",
        "\n",
        "    center_loss=difference(tf.cast(center_pred,dtype=tf.float32),tf.cast(center_target,dtype=tf.float32))\n",
        "\n",
        "\n",
        "\n",
        "    #------------------------------------------------------- for width and height\n",
        "\n",
        "    size_joined=tf.stack([y_pred_extract[...,3:5],y_pred_extract[...,8:10]],axis=-1)\n",
        "\n",
        "    size_pred=tf.gather_nd(size_joined,tf.stack([tf.range(len(rescaler)),mask],axis=-1))\n",
        "    size_target=tf.gather_nd(y_true[...,3:5],tf.where(target[:]==1))\n",
        "\n",
        "    size_loss=difference(tf.math.sqrt(tf.math.abs(tf.cast(size_pred,dtype=tf.float32))),tf.math.sqrt(tf.math.abs(tf.cast(size_target,dtype=tf.float32))))\n",
        "\n",
        "\n",
        "    box_loss=center_loss+size_loss\n",
        "\n",
        "    lambda_coord=5\n",
        "    lambda_no_obj=0.5\n",
        "\n",
        "    loss=object_loss+(lambda_no_obj*no_obj_loss)+tf.cast(lambda_coord*box_loss,dtype=tf.float32)+tf.cast(class_loss,dtype=tf.float32)\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#y_true=generate_output(np.array([[0.210784,0.616422,0.127451,0.232843,2]]))\n",
        "y_true=generate_output(np.array([[0.509804,0.411765,0.107843,0.245098,3],\n",
        "                       [0.210784,0.616422,0.127451,0.232843,2]]))\n",
        "\n",
        "y_true=np.expand_dims(y_true,axis=0)\n",
        "y_pred=np.random.normal(size = (1,7,7,30))\n",
        "\n",
        "y_pred[0][1][4] = [0.9,0.47,0.31,0.12,0.23,   1.0,0.2,0.6,0.1,0.95,    0.9,0.8,0.2,0.6,0.1,0.5,0.9,0.35,0.9,0.8,0.2,0.6,0.1,0.5,0.9,0.35,0.1,0.5,0.9,0.35]\n",
        "y_pred[0][3][2] = [0.3,0.01,0.08,0.11,0.54,   0.98,0.56,0.88,0.1,0.24, 0.09,0.018,0.22,0.16,0.01,0.05,0.99,0.3,0.09,0.018,0.22,0.16,0.01,0.05,0.99,0.3,0.01,0.05,0.99,0.3]\n",
        "\n",
        "yolo_loss(y_true,y_pred)\n",
        "!mkdir /kaggle/working/model\n",
        "checkpoint_filepath='/content/drive/MyDrive/Bang/yolo_efficientnet_b1_new.h5'\n",
        "callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  if epoch < 40:\n",
        "    return 1e-3\n",
        "  elif epoch>=40 and epoch<80:\n",
        "    return 5e-4\n",
        "  else:\n",
        "    return 1e-4\n",
        "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "model.compile(\n",
        "  loss=yolo_loss,\n",
        "  optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        ")\n",
        "history = model.fit(\n",
        "  train,\n",
        "  validation_data=val,\n",
        "  verbose=1,\n",
        "  epochs=15,\n",
        "  callbacks = [lr_callback,callback]`\n",
        ")\n",
        "def model_test(test_path):\n",
        "  try:\n",
        "\n",
        "    print(test_path)\n",
        "\n",
        "    img=cv2.resize(cv2.imread(test_path),(H,W))\n",
        "\n",
        "    image=tf.io.decode_jpeg(tf.io.read_file(test_path))\n",
        "    image=tf.image.resize(image, [H,W])\n",
        "\n",
        "    output=model.predict(np.expand_dims(image, axis = 0))\n",
        "\n",
        "    THRESH=.25\n",
        "\n",
        "    object_positions=tf.concat(\n",
        "        [tf.where(output[...,0]>=THRESH),tf.where(output[...,5]>=THRESH)],axis=0)\n",
        "    print(object_positions)\n",
        "    selected_output=tf.gather_nd(output,object_positions)\n",
        "    print(selected_output)\n",
        "    final_boxes=[]\n",
        "    final_scores=[]\n",
        "\n",
        "    for i,pos in enumerate(object_positions):\n",
        "      for j in range(2):\n",
        "        if selected_output[i][j*5]>THRESH:\n",
        "          output_box=tf.cast(output[pos[0]][pos[1]][pos[2]][(j*5)+1:(j*5)+5],dtype=tf.float32)\n",
        "\n",
        "          x_centre=(tf.cast(pos[1],dtype=tf.float32)+output_box[0])*32\n",
        "          y_centre=(tf.cast(pos[2],dtype=tf.float32)+output_box[1])*32\n",
        "\n",
        "          x_width,y_height=tf.math.abs(H*output_box[2]),tf.math.abs(W*output_box[3])\n",
        "\n",
        "          x_min,y_min=int(x_centre-(x_width/2)),int(y_centre-(y_height/2))\n",
        "          x_max,y_max=int(x_centre+(x_width/2)),int(y_centre+(y_height/2))\n",
        "\n",
        "          if(x_min<=0):x_min=0\n",
        "          if(y_min<=0):y_min=0\n",
        "          if(x_max>=W):x_max=W\n",
        "          if(y_max>=H):y_max=H\n",
        "          final_boxes.append(\n",
        "              [x_min,y_min,x_max,y_max,\n",
        "              str(classes[tf.argmax(selected_output[...,10:],axis=-1)[i]])])\n",
        "          final_scores.append(selected_output[i][j*5])\n",
        "    print(final_scores)\n",
        "    print('finalboxes',final_boxes)\n",
        "    final_boxes=np.array(final_boxes)\n",
        "\n",
        "    object_classes=final_boxes[...,4]\n",
        "    nms_boxes=final_boxes[...,0:4]\n",
        "\n",
        "    nms_output=tf.image.non_max_suppression(\n",
        "        nms_boxes,final_scores,max_output_size=100,iou_threshold=0.2,\n",
        "        score_threshold=float('-inf')\n",
        "    )\n",
        "    print(nms_output)\n",
        "\n",
        "    for i in nms_output:\n",
        "      cv2.rectangle(\n",
        "          img,\n",
        "          (int(final_boxes[i][0]),int(final_boxes[i][1])),\n",
        "          (int(final_boxes[i][2]),int(final_boxes[i][3])),(0,0,255),1)\n",
        "      cv2.putText(\n",
        "          img,\n",
        "          final_boxes[i][-1],\n",
        "          (int(final_boxes[i][0]),int(final_boxes[i][1])+15),\n",
        "          cv2.FONT_HERSHEY_COMPLEX_SMALL,1,(2,225,155),1\n",
        "          )\n",
        "\n",
        "    cv2.imwrite('/kaggle/working/'+filename[:-4]+'_det'+'.jpg',cv2.resize(img,(384,384)))\n",
        "  except:\n",
        "    print(\"NO object found !!!\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 1271215,
          "sourceId": 2118595,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30626,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}